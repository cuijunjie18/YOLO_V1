{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3957e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53930b6d",
   "metadata": {},
   "source": [
    "**一、定义对比实验的损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf283a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect_Loss(nn.Module):\n",
    "    def __init__(self, feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "        \"\"\"\n",
    "        初始化 YOLOv1 损失函数\n",
    "        \n",
    "        参数:\n",
    "        - feature_size: 特征图尺寸 (默认7x7)\n",
    "        - num_bboxes: 每个网格预测的边界框数量 (默认2)\n",
    "        - num_classes: 类别数量 (默认20)\n",
    "        - lambda_coord: 坐标损失的权重系数 (默认5.0)\n",
    "        - lambda_noobj: 无目标置信度损失的权重系数 (默认0.5)\n",
    "        \"\"\"\n",
    "        super(Detect_Loss, self).__init__()\n",
    "        \n",
    "        self.S = feature_size       # 特征图大小 (SxS 网格)\n",
    "        self.B = num_bboxes         # 每个网格预测的边界框数量\n",
    "        self.C = num_classes        # 类别数量\n",
    "        self.lambda_coord = lambda_coord  # 坐标损失权重\n",
    "        self.lambda_noobj = lambda_noobj  # 无目标置信度损失权重\n",
    "\n",
    "    def compute_iou(self, bbox1, bbox2):\n",
    "        \"\"\"\n",
    "        计算两组边界框之间的交并比(IoU)\n",
    "        \n",
    "        参数:\n",
    "        - bbox1: 形状为 [N, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        - bbox2: 形状为 [M, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        \n",
    "        返回:\n",
    "        - iou: 形状为 [N, M] 的 IoU 矩阵\n",
    "        \"\"\"\n",
    "        # 获取边界框数量\n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "        \n",
    "        # 计算交集的左上角坐标 (left-top)\n",
    "        lt = torch.max(\n",
    "            bbox1[:, :2].unsqueeze(1).expand(N, M, 2),  # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, :2].unsqueeze(0).expand(N, M, 2)   # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        \n",
    "        # 计算交集的右下角坐标 (right-bottom)\n",
    "        rb = torch.min(\n",
    "            bbox1[:, 2:].unsqueeze(1).expand(N, M, 2),  # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)    # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        \n",
    "        # 计算交集的宽高\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0  # 处理无重叠的情况\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1]  # 交集面积 [N, M]\n",
    "        \n",
    "        # 计算两个边界框各自的面积\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1])  # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1])  # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter)  # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter)  # [M, ] -> [1, M] -> [N, M]\n",
    "        \n",
    "        # 计算并集面积\n",
    "        union = area1 + area2 - inter  # [N, M]\n",
    "\n",
    "        print(f\"area1:{area1}\")\n",
    "        print(f\"area2:{area2}\")\n",
    "        print(f\"inter:{inter}\")\n",
    "        print(f\"union:{union}\")\n",
    "        \n",
    "        # 计算 IoU\n",
    "        iou = inter / union  # [N, M]\n",
    "        \n",
    "        return iou\n",
    "\n",
    "    def forward(self, pred_tensor, target_tensor):\n",
    "        \"\"\"\n",
    "        计算 YOLOv1 损失\n",
    "        \n",
    "        参数:\n",
    "        - pred_tensor: 模型预测的输出张量，形状为 [batch_size, S, S, B*5 + C]\n",
    "        - target_tensor: 目标标签张量，形状与 pred_tensor 相同\n",
    "        \n",
    "        返回:\n",
    "        - loss: 计算得到的损失值\n",
    "        \"\"\"\n",
    "        # 获取参数\n",
    "        S, B, C = self.S, self.B, self.C\n",
    "        N = 5 * B + C  # 每个网格的预测值总数\n",
    "        \n",
    "        batch_size = pred_tensor.size(0)\n",
    "        \n",
    "        # 创建目标存在和不存在的位置掩码\n",
    "        # target_tensor[:, :, :, 4] 是第一个边界框的置信度\n",
    "        coord_mask = target_tensor[:, :, :, 4] > 0   # 有目标的网格位置\n",
    "        noobj_mask = target_tensor[:, :, :, 4] == 0  # 无目标的网格位置\n",
    "        \n",
    "        # 扩展掩码维度以匹配目标张量\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "        \n",
    "        # 提取有目标位置的预测值和目标值\n",
    "        coord_pred = pred_tensor[coord_mask].view(-1, N)\n",
    "        coord_target = target_tensor[coord_mask].view(-1, N)\n",
    "        \n",
    "        # 分割边界框预测和类别预测\n",
    "        bbox_pred = coord_pred[:, :5 * B].contiguous().view(-1, 5)\n",
    "        class_pred = coord_pred[:, 5 * B:]\n",
    "        \n",
    "        # 分割边界框目标和类别目标\n",
    "        bbox_target = coord_target[:, :5 * B].contiguous().view(-1, 5)\n",
    "        class_target = coord_target[:, 5 * B:]\n",
    "        \n",
    "        # 提取无目标位置的预测值和目标值\n",
    "        noobj_pred = pred_tensor[noobj_mask].view(-1, N)\n",
    "        noobj_target = target_tensor[noobj_mask].view(-1, N)\n",
    "        \n",
    "        # 处理无目标位置的置信度损失\n",
    "        # 创建掩码以选择所有边界框的置信度 (位置 4, 9, ...)\n",
    "        noobj_conf_mask = torch.BoolTensor(noobj_pred.size()).fill_(0)\n",
    "        for b in range(B):\n",
    "            noobj_conf_mask[:, 4 + b * 5] = 1  # 设置每个边界框的置信度位置\n",
    "            \n",
    "        # 提取无目标位置的置信度预测值和目标值\n",
    "        noobj_pred_conf = noobj_pred[noobj_conf_mask]\n",
    "        noobj_target_conf = noobj_target[noobj_conf_mask]\n",
    "        \n",
    "        # 计算无目标的置信度损失\n",
    "        loss_noobj = F.mse_loss(noobj_pred_conf, noobj_target_conf, reduction='sum')\n",
    "        \n",
    "        # 初始化响应掩码\n",
    "        coord_response_mask = torch.BoolTensor(bbox_target.size()).fill_(0)\n",
    "        coord_not_response_mask = torch.BoolTensor(bbox_target.size()).fill_(1)\n",
    "        bbox_target_iou = torch.zeros(bbox_target.size())\n",
    "        \n",
    "        # 遍历每个有目标的网格\n",
    "        for i in range(0, bbox_target.size(0), B):\n",
    "            # 获取当前网格的 B 个预测边界框\n",
    "            pred = bbox_pred[i:i + B]\n",
    "            \n",
    "            # 将预测边界框转换为 (xmin, ymin, xmax, ymax) 格式\n",
    "            pred_xyxy = Variable(torch.FloatTensor(pred.size()))\n",
    "            pred_xyxy[:, :2] = pred[:, :2] / float(S) - 0.5 * pred[:, 2:4]  # 左上角\n",
    "            pred_xyxy[:, 2:4] = pred[:, :2] / float(S) + 0.5 * pred[:, 2:4]  # 右下角\n",
    "            \n",
    "            # 获取当前网格的目标边界框\n",
    "            target = bbox_target[i].view(-1, 5)\n",
    "            \n",
    "            # 将目标边界框转换为 (xmin, ymin, xmax, ymax) 格式\n",
    "            target_xyxy = Variable(torch.FloatTensor(target.size()))\n",
    "            target_xyxy[:, :2] = target[:, :2] / float(S) - 0.5 * target[:, 2:4]  # 左上角\n",
    "            target_xyxy[:, 2:4] = target[:, :2] / float(S) + 0.5 * target[:, 2:4]  # 右下角\n",
    "            \n",
    "            # 计算预测边界框与目标边界框的 IoU\n",
    "            iou = self.compute_iou(pred_xyxy[:, :4], target_xyxy[:, :4])\n",
    "            max_iou, max_index = iou.max(0)  # 找出最大 IoU 及其索引\n",
    "            max_index = max_index.data\n",
    "            \n",
    "            # 标记负责预测目标的边界框\n",
    "            coord_response_mask[i + max_index] = 1\n",
    "            coord_not_response_mask[i + max_index] = 0\n",
    "            \n",
    "            # 将最大 IoU 作为置信度目标\n",
    "            bbox_target_iou[i + max_index, torch.LongTensor([4])] = max_iou.data\n",
    "        \n",
    "        bbox_target_iou = Variable(bbox_target_iou)\n",
    "        \n",
    "        # 提取负责预测目标的边界框\n",
    "        bbox_pred_response = bbox_pred[coord_response_mask].view(-1, 5)\n",
    "        bbox_target_response = bbox_target[coord_response_mask].view(-1, 5)\n",
    "        target_iou = bbox_target_iou[coord_response_mask].view(-1, 5)\n",
    "        \n",
    "        # 计算坐标损失 (中心点坐标)\n",
    "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
    "        \n",
    "        # 计算宽高损失 (使用平方根以平衡大小目标)\n",
    "        loss_wh = F.mse_loss(\n",
    "            torch.sqrt(bbox_pred_response[:, 2:4]), \n",
    "            torch.sqrt(bbox_target_response[:, 2:4]),\n",
    "            reduction='sum'\n",
    "        )\n",
    "        \n",
    "        # 计算有目标的置信度损失\n",
    "        loss_obj = F.mse_loss(bbox_pred_response[:, 4], target_iou[:, 4], reduction='sum')\n",
    "        \n",
    "        # 计算类别损失\n",
    "        loss_class = F.mse_loss(class_pred, class_target, reduction='sum')\n",
    "\n",
    "        print(loss_xy,loss_wh,loss_class,loss_obj,loss_noobj)\n",
    "        \n",
    "        # 计算总损失\n",
    "        loss = (\n",
    "            self.lambda_coord * (loss_xy + loss_wh) +  # 坐标损失\n",
    "            loss_obj +                                # 有目标的置信度损失\n",
    "            self.lambda_noobj * loss_noobj +           # 无目标的置信度损失\n",
    "            loss_class                                # 类别损失\n",
    "        )\n",
    "\n",
    "        print(target_iou[:,4])\n",
    "        \n",
    "        # 平均损失\n",
    "        loss = loss / float(batch_size)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454cdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    \"\"\"定义一个为yolov1的损失函数\"\"\"\n",
    "\n",
    "    def __init__(self,feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "        super().__init__()\n",
    "        self.S = feature_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "    def compute_iou(self,bbox1,bbox2):\n",
    "        \"\"\"\"\n",
    "        计算两组边界框之间的交并比(IoU)\n",
    "        \n",
    "        参数:\n",
    "        - bbox1: 形状为 [N, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        - bbox2: 形状为 [M, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        \n",
    "        返回:\n",
    "        - iou: 形状为 [N, M] 的 IoU 矩阵\n",
    "        \"\"\"\n",
    "        # 获取边界框数量\n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "        \n",
    "        # 计算交集的左上角坐标 (left-top)\n",
    "        lt = torch.max(\n",
    "            bbox1[:, :2].unsqueeze(1).expand(N, M, 2),  # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, :2].unsqueeze(0).expand(N, M, 2)   # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        \n",
    "        # 计算交集的右下角坐标 (right-bottom)\n",
    "        rb = torch.min(\n",
    "            bbox1[:, 2:].unsqueeze(1).expand(N, M, 2),  # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)    # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        \n",
    "        # 计算交集的宽高\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0  # 处理无重叠的情况\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1]  # 交集面积 [N, M]\n",
    "        \n",
    "        # 计算两个边界框各自的面积\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1])  # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1])  # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter)  # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter)  # [M, ] -> [1, M] -> [N, M]\n",
    "        \n",
    "        # 计算并集面积\n",
    "        union = area1 + area2 - inter  # [N, M]\n",
    "        \n",
    "        # 计算 IoU\n",
    "        iou = inter / union  # [N, M]\n",
    "        \n",
    "        return iou\n",
    "\n",
    "\n",
    "    def forward(self,pred:torch.Tensor,target:torch.Tensor):\n",
    "        \"\"\"\n",
    "        计算 YOLOv1 损失\n",
    "        \n",
    "        参数:\n",
    "        - pred_tensor: 模型预测的输出张量，形状为 [batch_size, S, S, B*5 + C]\n",
    "        - target_tensor: 目标标签张量，形状与 pred_tensor 相同\n",
    "        \n",
    "        返回:\n",
    "        - loss: 计算得到的损失值\n",
    "        \"\"\"\n",
    "        # target/pred = (N,C,H,W) -> (N,H,W,C)\n",
    "        target = target.permute(0,2,3,1)\n",
    "        pred = pred.permute(0,2,3,1)\n",
    "        batch_size = pred.shape[0]\n",
    "\n",
    "        # 设置临时参数，减少重复self引用\n",
    "        S = self.S\n",
    "        B = self.B\n",
    "        C = self.C\n",
    "        grid_size = 1.0 / S # 归一化的网格大小\n",
    "\n",
    "        # 设置有目标的mask和没目标的mask\n",
    "        coord_mask = target[:,:,:,4] > 0\n",
    "        noobj_mask = target[:,:,:,4] == 0\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target)\n",
    "\n",
    "        # 提取有目标的pred和没目标的pred\n",
    "        coord_pred = pred[coord_mask].reshape(-1, 5 * B + C)\n",
    "        noobj_pred = pred[noobj_mask].reshape(-1, 5 * B + C)\n",
    "\n",
    "        # 提取有目标的target和没目标的target\n",
    "        coord_target = target[coord_mask].reshape(-1, 5 * B + C)\n",
    "        noobj_target = target[noobj_mask].reshape(-1, 5 * B + C)\n",
    "\n",
    "        # 提取bbox与class\n",
    "        bbox_pred = coord_pred[:,:5 * B].reshape(-1, 5)\n",
    "        class_pred = coord_pred[:,5 * B:]\n",
    "        bbox_target = coord_target[:,:5 * B].reshape(-1, 5)\n",
    "        class_target = coord_target[:,5 * B:]\n",
    "\n",
    "        # 处理无目标位置的置信度损失\n",
    "        noobj_conf_mask = torch.BoolTensor(noobj_pred.shape).fill_(0)\n",
    "        for b in range(B):\n",
    "            noobj_conf_mask[:,4 + b * 5] = 1 # 设置提取出置信度的位置\n",
    "        noobj_conf_pred = noobj_pred[noobj_conf_mask]\n",
    "        noonj_conf_target = noobj_target[noobj_conf_mask]\n",
    "\n",
    "        # 计算noobj_loss_conf\n",
    "        loss_conf_noobj = F.mse_loss(noobj_conf_pred,noonj_conf_target,reduction = 'sum')\n",
    "\n",
    "        # 初始化响应掩码\n",
    "        coord_response_mask = torch.BoolTensor(bbox_target.size()).fill_(0) # 响应初始化为0\n",
    "        coord_not_response_mask = torch.BoolTensor(bbox_target.size()).fill_(1) # 非响应初始化为1\n",
    "        bbox_target_iou = torch.zeros(bbox_target.size())\n",
    "\n",
    "        # 遍历每个目标网格\n",
    "        for i in range(0,bbox_pred.shape[0],B):\n",
    "            # 获取当前网格的 B 个预测边界框\n",
    "            pred = bbox_pred[i:i + B] \n",
    "\n",
    "            # 将预测边界框转换为 (xmin, ymin, xmax, ymax) 格式\n",
    "            pred_xyxy = torch.zeros((pred.shape[0],4))\n",
    "            pred_xyxy[:,:2] = pred[:,:2] * grid_size - pred[:,2:4] * 0.5    # 左上\n",
    "            pred_xyxy[:,2:4] = pred[:,:2] * grid_size + pred[:,2:4] * 0.5   # 右下\n",
    "\n",
    "            # 同样处理出目标坐标\n",
    "            target = bbox_target[i].reshape(-1,5)\n",
    "            target_xyxy = torch.zeros((target.shape[0],4))\n",
    "            target_xyxy[:,:2] = target[:,:2] * grid_size - target[:,2:4] * 0.5    # 左上\n",
    "            target_xyxy[:,2:4] = target[:,:2] * grid_size + target[:,2:4] * 0.5   # 右下\n",
    "\n",
    "            # 计算iou\n",
    "            iou = self.compute_iou(pred_xyxy,target_xyxy)\n",
    "            max_iou, max_index = iou.max(0)  # 找出最大 IoU 及其索引\n",
    "\n",
    "            # 标记负责预测目标的边界框\n",
    "            coord_response_mask[i + max_index] = 1\n",
    "            coord_not_response_mask[i + max_index] = 0\n",
    "\n",
    "            # 将最大 IoU 作为置信度目标\n",
    "            bbox_target_iou[i + max_index,4] = max_iou.data\n",
    "\n",
    "        # 提取负责预测目标的边界框\n",
    "        bbox_pred_response = bbox_pred[coord_response_mask].reshape(-1, 5)\n",
    "        bbox_target_response = bbox_target[coord_response_mask].reshape(-1, 5)\n",
    "        target_iou = bbox_target_iou[coord_response_mask].reshape(-1, 5)\n",
    "\n",
    "        # 计算坐标损失 (中心点坐标)\n",
    "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
    "        \n",
    "        # 计算宽高损失\n",
    "        loss_wh = F.mse_loss(\n",
    "            torch.sqrt(bbox_pred_response[:,2:4]), \n",
    "            torch.sqrt(bbox_target_response[:,2:4]), \n",
    "            reduction = 'sum'\n",
    "        )\n",
    "\n",
    "        # 计算目标置信度损失\n",
    "        loss_conf = F.mse_loss(bbox_pred_response[:,4], target_iou[:,4], reduction = 'sum')\n",
    "\n",
    "        # 计算类别预测损失\n",
    "        loss_class = F.mse_loss(class_pred,class_target,reduction = 'sum')\n",
    "\n",
    "        print(loss_xy,loss_wh,loss_class,loss_conf,loss_conf_noobj)\n",
    "        print(target_iou[:,4])\n",
    "\n",
    "        loss = (self.lambda_coord * (loss_xy + loss_wh) + \n",
    "                self.lambda_noobj * loss_conf_noobj +\n",
    "                loss_conf + loss_class)\n",
    "        \n",
    "        return loss / batch_size # 平均损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37b3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = YoloLoss()\n",
    "loss_re = Detect_Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869df949",
   "metadata": {},
   "source": [
    "**二、使用模拟数据进行测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249ebdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((2,2))\n",
    "mask = torch.BoolTensor([[1,1],[0,0]])\n",
    "x[mask] = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57986865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2158, 0.2821, 0.9558,  ..., 0.4798, 0.9295, 0.3823],\n",
      "          [0.0816, 0.0926, 0.0541,  ..., 0.3415, 0.0306, 0.3047],\n",
      "          [0.9612, 0.9019, 0.9599,  ..., 0.0712, 0.1078, 0.5176],\n",
      "          ...,\n",
      "          [0.2794, 0.7994, 0.1757,  ..., 0.8147, 0.4747, 0.4636],\n",
      "          [0.7510, 0.1080, 0.1513,  ..., 0.5053, 0.7625, 0.1219],\n",
      "          [0.0171, 0.4174, 0.7365,  ..., 0.6677, 0.0775, 0.0607]],\n",
      "\n",
      "         [[0.4462, 0.2831, 0.0937,  ..., 0.8535, 0.6818, 0.0599],\n",
      "          [0.6610, 0.2590, 0.9078,  ..., 0.8604, 0.7817, 0.2669],\n",
      "          [0.2906, 0.2111, 0.1386,  ..., 0.3150, 0.2995, 0.5360],\n",
      "          ...,\n",
      "          [0.4548, 0.8751, 0.1952,  ..., 0.5851, 0.5643, 0.7813],\n",
      "          [0.7334, 0.0064, 0.0306,  ..., 0.2229, 0.3323, 0.7264],\n",
      "          [0.6790, 0.6386, 0.1395,  ..., 0.1862, 0.9604, 0.9897]],\n",
      "\n",
      "         [[0.8988, 0.2368, 0.0042,  ..., 0.2239, 0.6410, 0.2715],\n",
      "          [0.5148, 0.1990, 0.2846,  ..., 0.9398, 0.2717, 0.3210],\n",
      "          [0.1441, 0.3453, 0.9593,  ..., 0.4984, 0.4926, 0.8012],\n",
      "          ...,\n",
      "          [0.7955, 0.1884, 0.7463,  ..., 0.0289, 0.4778, 0.5575],\n",
      "          [0.7983, 0.5017, 0.6486,  ..., 0.1868, 0.6202, 0.6172],\n",
      "          [0.9249, 0.6235, 0.5459,  ..., 0.4280, 0.4909, 0.6594]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0566, 0.7119, 0.4767,  ..., 0.3039, 0.4891, 0.8775],\n",
      "          [0.9729, 0.8480, 0.2870,  ..., 0.4441, 0.8476, 0.2332],\n",
      "          [0.6131, 0.7968, 0.6086,  ..., 0.2043, 0.2739, 0.4206],\n",
      "          ...,\n",
      "          [0.4097, 0.4531, 0.5141,  ..., 0.6843, 0.5806, 0.9084],\n",
      "          [0.6646, 0.8838, 0.6367,  ..., 0.4018, 0.3560, 0.3939],\n",
      "          [0.9385, 0.6040, 0.4615,  ..., 0.4606, 0.4209, 0.8784]],\n",
      "\n",
      "         [[0.0921, 0.1836, 0.4423,  ..., 0.9557, 0.5833, 0.9318],\n",
      "          [0.6936, 0.6011, 0.3939,  ..., 0.4954, 0.7371, 0.7965],\n",
      "          [0.0792, 0.1037, 0.1350,  ..., 0.6258, 0.4240, 0.6278],\n",
      "          ...,\n",
      "          [0.5646, 0.0021, 0.6987,  ..., 0.2356, 0.6467, 0.2884],\n",
      "          [0.3424, 0.7854, 0.5894,  ..., 0.8208, 0.6106, 0.4013],\n",
      "          [0.5399, 0.3597, 0.4273,  ..., 0.0402, 0.1148, 0.5849]],\n",
      "\n",
      "         [[0.5718, 0.1478, 0.2893,  ..., 0.0917, 0.3619, 0.7542],\n",
      "          [0.9245, 0.1987, 0.6789,  ..., 0.9432, 0.1116, 0.3459],\n",
      "          [0.5989, 0.9477, 0.7392,  ..., 0.4987, 0.1942, 0.5032],\n",
      "          ...,\n",
      "          [0.1735, 0.7282, 0.1573,  ..., 0.4296, 0.6856, 0.1308],\n",
      "          [0.8015, 0.3692, 0.9298,  ..., 0.8173, 0.6989, 0.9103],\n",
      "          [0.7605, 0.9926, 0.5105,  ..., 0.3094, 0.1015, 0.5078]]]])\n"
     ]
    }
   ],
   "source": [
    "# 注意要符合数据的要求，归一化后数值0~1\n",
    "pre = torch.rand(1,30,7,7)  # 随机预测张量 [batch, S, S, B*5+C]\n",
    "tar = torch.rand(1,30,7,7)  # 随机目标张量\n",
    "mask1 = pre > 0\n",
    "mask2 = tar > 0\n",
    "pre[~mask1] = 0\n",
    "tar[~mask2] = 0\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb05cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.5471) tensor(8.4643) tensor(165.0612) tensor(5.0647) tensor(0.)\n",
      "tensor([0.2146, 0.2720, 0.6098, 0.8204, 0.0870, 0.4029, 0.0415, 0.4995, 0.1205,\n",
      "        0.3979, 0.1811, 0.1378, 0.1988, 0.3447, 0.7174, 0.2653, 0.4863, 0.1401,\n",
      "        0.5357, 0.6598, 0.1047, 0.0281, 0.2956, 0.7181, 0.0441, 0.0713, 0.2138,\n",
      "        0.3064, 0.5588, 0.1828, 0.5447, 0.1025, 0.0811, 0.4417, 0.1836, 0.5270,\n",
      "        0.4007, 0.7100, 0.2439, 0.2870, 0.4854, 0.5427, 0.6053, 0.5066, 0.5535,\n",
      "        0.2310, 0.1016, 0.4932, 0.2306])\n"
     ]
    }
   ],
   "source": [
    "out1 = loss(pre,tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb8cbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area1:tensor([[0.1848],\n",
      "        [0.0443]])\n",
      "area2:tensor([[0.1529],\n",
      "        [0.1529]])\n",
      "inter:tensor([[0.0420],\n",
      "        [0.0349]])\n",
      "union:tensor([[0.2957],\n",
      "        [0.1624]])\n",
      "area1:tensor([[0.0873],\n",
      "        [0.6769]])\n",
      "area2:tensor([[0.1289],\n",
      "        [0.1289]])\n",
      "inter:tensor([[0.0462],\n",
      "        [0.1286]])\n",
      "union:tensor([[0.1699],\n",
      "        [0.6772]])\n",
      "area1:tensor([[0.0015],\n",
      "        [0.3927]])\n",
      "area2:tensor([[0.4557],\n",
      "        [0.4557]])\n",
      "inter:tensor([[0.0015],\n",
      "        [0.3214]])\n",
      "union:tensor([[0.4557],\n",
      "        [0.5270]])\n",
      "area1:tensor([[0.4795],\n",
      "        [0.6982]])\n",
      "area2:tensor([[0.6269],\n",
      "        [0.6269]])\n",
      "inter:tensor([[0.4247],\n",
      "        [0.5972]])\n",
      "union:tensor([[0.6817],\n",
      "        [0.7279]])\n",
      "area1:tensor([[0.1829],\n",
      "        [0.3183]])\n",
      "area2:tensor([[0.0177],\n",
      "        [0.0177]])\n",
      "inter:tensor([[0.0161],\n",
      "        [0.0074]])\n",
      "union:tensor([[0.1846],\n",
      "        [0.3286]])\n",
      "area1:tensor([[0.3830],\n",
      "        [0.1016]])\n",
      "area2:tensor([[0.9505],\n",
      "        [0.9505]])\n",
      "inter:tensor([[0.3830],\n",
      "        [0.1016]])\n",
      "union:tensor([[0.9505],\n",
      "        [0.9505]])\n",
      "area1:tensor([[0.2202],\n",
      "        [0.0962]])\n",
      "area2:tensor([[0.0310],\n",
      "        [0.0310]])\n",
      "inter:tensor([[0.0100],\n",
      "        [0.0043]])\n",
      "union:tensor([[0.2412],\n",
      "        [0.1229]])\n",
      "area1:tensor([[0.3993],\n",
      "        [0.1994]])\n",
      "area2:tensor([[0.2211],\n",
      "        [0.2211]])\n",
      "inter:tensor([[0.1998],\n",
      "        [0.1401]])\n",
      "union:tensor([[0.4207],\n",
      "        [0.2805]])\n",
      "area1:tensor([[0.0054],\n",
      "        [0.9160]])\n",
      "area2:tensor([[0.1104],\n",
      "        [0.1104]])\n",
      "inter:tensor([[0.0040],\n",
      "        [0.1104]])\n",
      "union:tensor([[0.1118],\n",
      "        [0.9160]])\n",
      "area1:tensor([[0.1433],\n",
      "        [0.0783]])\n",
      "area2:tensor([[0.0696],\n",
      "        [0.0696]])\n",
      "inter:tensor([[0.0606],\n",
      "        [0.0356]])\n",
      "union:tensor([[0.1523],\n",
      "        [0.1123]])\n",
      "area1:tensor([[0.0582],\n",
      "        [0.4993]])\n",
      "area2:tensor([[0.0573],\n",
      "        [0.0573]])\n",
      "inter:tensor([[0.0177],\n",
      "        [0.0573]])\n",
      "union:tensor([[0.0978],\n",
      "        [0.4993]])\n",
      "area1:tensor([[0.5500],\n",
      "        [0.1225]])\n",
      "area2:tensor([[0.0554],\n",
      "        [0.0554]])\n",
      "inter:tensor([[0.0429],\n",
      "        [0.0215]])\n",
      "union:tensor([[0.5625],\n",
      "        [0.1564]])\n",
      "area1:tensor([[0.2002],\n",
      "        [0.3351]])\n",
      "area2:tensor([[0.0637],\n",
      "        [0.0637]])\n",
      "inter:tensor([[0.0438],\n",
      "        [0.0637]])\n",
      "union:tensor([[0.2201],\n",
      "        [0.3351]])\n",
      "area1:tensor([[0.0209],\n",
      "        [0.3004]])\n",
      "area2:tensor([[0.0294],\n",
      "        [0.0294]])\n",
      "inter:tensor([[0.0129],\n",
      "        [0.0294]])\n",
      "union:tensor([[0.0374],\n",
      "        [0.3004]])\n",
      "area1:tensor([[0.0872],\n",
      "        [0.1624]])\n",
      "area2:tensor([[0.1974],\n",
      "        [0.1974]])\n",
      "inter:tensor([[0.0426],\n",
      "        [0.1503]])\n",
      "union:tensor([[0.2420],\n",
      "        [0.2095]])\n",
      "area1:tensor([[0.1213],\n",
      "        [0.0042]])\n",
      "area2:tensor([[0.4571],\n",
      "        [0.4571]])\n",
      "inter:tensor([[0.1213],\n",
      "        [0.0026]])\n",
      "union:tensor([[0.4571],\n",
      "        [0.4586]])\n",
      "area1:tensor([[0.1558],\n",
      "        [0.0023]])\n",
      "area2:tensor([[0.2331],\n",
      "        [0.2331]])\n",
      "inter:tensor([[0.1272],\n",
      "        [0.0011]])\n",
      "union:tensor([[0.2616],\n",
      "        [0.2343]])\n",
      "area1:tensor([[0.0479],\n",
      "        [0.0221]])\n",
      "area2:tensor([[0.1577],\n",
      "        [0.1577]])\n",
      "inter:tensor([[0.0219],\n",
      "        [0.0221]])\n",
      "union:tensor([[0.1837],\n",
      "        [0.1577]])\n",
      "area1:tensor([[0.4202],\n",
      "        [0.4784]])\n",
      "area2:tensor([[0.7714],\n",
      "        [0.7714]])\n",
      "inter:tensor([[0.4157],\n",
      "        [0.4185]])\n",
      "union:tensor([[0.7760],\n",
      "        [0.8313]])\n",
      "area1:tensor([[0.2722],\n",
      "        [0.2618]])\n",
      "area2:tensor([[0.3967],\n",
      "        [0.3967]])\n",
      "inter:tensor([[0.2172],\n",
      "        [0.2618]])\n",
      "union:tensor([[0.4517],\n",
      "        [0.3967]])\n",
      "area1:tensor([[0.0845],\n",
      "        [0.0434]])\n",
      "area2:tensor([[0.0348],\n",
      "        [0.0348]])\n",
      "inter:tensor([[0.0089],\n",
      "        [0.0074]])\n",
      "union:tensor([[0.1104],\n",
      "        [0.0708]])\n",
      "area1:tensor([[0.3999],\n",
      "        [0.0712]])\n",
      "area2:tensor([[0.0050],\n",
      "        [0.0050]])\n",
      "inter:tensor([[0.0050],\n",
      "        [0.0021]])\n",
      "union:tensor([[0.3999],\n",
      "        [0.0741]])\n",
      "area1:tensor([[0.0634],\n",
      "        [0.1141]])\n",
      "area2:tensor([[0.0612],\n",
      "        [0.0612]])\n",
      "inter:tensor([[0.0152],\n",
      "        [0.0400]])\n",
      "union:tensor([[0.1093],\n",
      "        [0.1353]])\n",
      "area1:tensor([[0.5432],\n",
      "        [0.4282]])\n",
      "area2:tensor([[0.4925],\n",
      "        [0.4925]])\n",
      "inter:tensor([[0.3508],\n",
      "        [0.3848]])\n",
      "union:tensor([[0.6849],\n",
      "        [0.5359]])\n",
      "area1:tensor([[0.2457],\n",
      "        [0.2616]])\n",
      "area2:tensor([[0.0226],\n",
      "        [0.0226]])\n",
      "inter:tensor([[0.0080],\n",
      "        [0.0120]])\n",
      "union:tensor([[0.2603],\n",
      "        [0.2722]])\n",
      "area1:tensor([[0.0890],\n",
      "        [0.6923]])\n",
      "area2:tensor([[0.0427],\n",
      "        [0.0427]])\n",
      "inter:tensor([[0.0088],\n",
      "        [0.0379]])\n",
      "union:tensor([[0.1229],\n",
      "        [0.6972]])\n",
      "area1:tensor([[0.0740],\n",
      "        [0.2578]])\n",
      "area2:tensor([[0.0447],\n",
      "        [0.0447]])\n",
      "inter:tensor([[0.0209],\n",
      "        [0.0447]])\n",
      "union:tensor([[0.0978],\n",
      "        [0.2578]])\n",
      "area1:tensor([[0.0116],\n",
      "        [0.0882]])\n",
      "area2:tensor([[0.0560],\n",
      "        [0.0560]])\n",
      "inter:tensor([[0.0045],\n",
      "        [0.0338]])\n",
      "union:tensor([[0.0631],\n",
      "        [0.1104]])\n",
      "area1:tensor([[0.4010],\n",
      "        [0.0373]])\n",
      "area2:tensor([[0.6576],\n",
      "        [0.6576]])\n",
      "inter:tensor([[0.3795],\n",
      "        [0.0373]])\n",
      "union:tensor([[0.6791],\n",
      "        [0.6576]])\n",
      "area1:tensor([[0.0257],\n",
      "        [0.0082]])\n",
      "area2:tensor([[0.0948],\n",
      "        [0.0948]])\n",
      "inter:tensor([[0.0186],\n",
      "        [0.0047]])\n",
      "union:tensor([[0.1018],\n",
      "        [0.0982]])\n",
      "area1:tensor([[0.0945],\n",
      "        [0.1462]])\n",
      "area2:tensor([[0.0807],\n",
      "        [0.0807]])\n",
      "inter:tensor([[0.0389],\n",
      "        [0.0800]])\n",
      "union:tensor([[0.1363],\n",
      "        [0.1469]])\n",
      "area1:tensor([[0.5568],\n",
      "        [0.2985]])\n",
      "area2:tensor([[0.0306],\n",
      "        [0.0306]])\n",
      "inter:tensor([[0.0306],\n",
      "        [0.0306]])\n",
      "union:tensor([[0.5568],\n",
      "        [0.2985]])\n",
      "area1:tensor([[0.0152],\n",
      "        [0.1256]])\n",
      "area2:tensor([[0.0102],\n",
      "        [0.0102]])\n",
      "inter:tensor([[0.0000],\n",
      "        [0.0102]])\n",
      "union:tensor([[0.0254],\n",
      "        [0.1256]])\n",
      "area1:tensor([[0.4227],\n",
      "        [0.1048]])\n",
      "area2:tensor([[0.2535],\n",
      "        [0.2535]])\n",
      "inter:tensor([[0.2072],\n",
      "        [0.0845]])\n",
      "union:tensor([[0.4690],\n",
      "        [0.2737]])\n",
      "area1:tensor([[0.3877],\n",
      "        [0.5203]])\n",
      "area2:tensor([[0.0712],\n",
      "        [0.0712]])\n",
      "inter:tensor([[0.0712],\n",
      "        [0.0712]])\n",
      "union:tensor([[0.3877],\n",
      "        [0.5203]])\n",
      "area1:tensor([[0.0011],\n",
      "        [0.5631]])\n",
      "area2:tensor([[0.4725],\n",
      "        [0.4725]])\n",
      "inter:tensor([[0.0010],\n",
      "        [0.3574]])\n",
      "union:tensor([[0.4726],\n",
      "        [0.6782]])\n",
      "area1:tensor([[0.1729],\n",
      "        [0.0058]])\n",
      "area2:tensor([[0.1109],\n",
      "        [0.1109]])\n",
      "inter:tensor([[0.0812],\n",
      "        [0.0052]])\n",
      "union:tensor([[0.2027],\n",
      "        [0.1115]])\n",
      "area1:tensor([[0.1668],\n",
      "        [0.5074]])\n",
      "area2:tensor([[0.4162],\n",
      "        [0.4162]])\n",
      "inter:tensor([[0.1213],\n",
      "        [0.3835]])\n",
      "union:tensor([[0.4617],\n",
      "        [0.5401]])\n",
      "area1:tensor([[0.2025],\n",
      "        [0.0028]])\n",
      "area2:tensor([[0.1032],\n",
      "        [0.1032]])\n",
      "inter:tensor([[0.0599],\n",
      "        [0.0028]])\n",
      "union:tensor([[0.2457],\n",
      "        [0.1032]])\n",
      "area1:tensor([[0.0110],\n",
      "        [0.1498]])\n",
      "area2:tensor([[0.0384],\n",
      "        [0.0384]])\n",
      "inter:tensor([[0.0110],\n",
      "        [0.0384]])\n",
      "union:tensor([[0.0384],\n",
      "        [0.1498]])\n",
      "area1:tensor([[0.1207],\n",
      "        [0.0459]])\n",
      "area2:tensor([[0.0846],\n",
      "        [0.0846]])\n",
      "inter:tensor([[0.0671],\n",
      "        [0.0115]])\n",
      "union:tensor([[0.1382],\n",
      "        [0.1190]])\n",
      "area1:tensor([[0.2863],\n",
      "        [0.1760]])\n",
      "area2:tensor([[0.3397],\n",
      "        [0.3397]])\n",
      "inter:tensor([[0.2202],\n",
      "        [0.1284]])\n",
      "union:tensor([[0.4057],\n",
      "        [0.3874]])\n",
      "area1:tensor([[0.2079],\n",
      "        [0.3991]])\n",
      "area2:tensor([[0.4303],\n",
      "        [0.4303]])\n",
      "inter:tensor([[0.1780],\n",
      "        [0.3127]])\n",
      "union:tensor([[0.4602],\n",
      "        [0.5166]])\n",
      "area1:tensor([[0.5676],\n",
      "        [0.8143]])\n",
      "area2:tensor([[0.3403],\n",
      "        [0.3403]])\n",
      "inter:tensor([[0.3053],\n",
      "        [0.3403]])\n",
      "union:tensor([[0.6026],\n",
      "        [0.8143]])\n",
      "area1:tensor([[0.2365],\n",
      "        [0.6349]])\n",
      "area2:tensor([[0.1596],\n",
      "        [0.1596]])\n",
      "inter:tensor([[0.1411],\n",
      "        [0.1526]])\n",
      "union:tensor([[0.2550],\n",
      "        [0.6419]])\n",
      "area1:tensor([[0.1558],\n",
      "        [0.0290]])\n",
      "area2:tensor([[0.0747],\n",
      "        [0.0747]])\n",
      "inter:tensor([[0.0433],\n",
      "        [0.0064]])\n",
      "union:tensor([[0.1872],\n",
      "        [0.0973]])\n",
      "area1:tensor([[0.1348],\n",
      "        [0.2083]])\n",
      "area2:tensor([[0.0377],\n",
      "        [0.0377]])\n",
      "inter:tensor([[0.0159],\n",
      "        [0.0159]])\n",
      "union:tensor([[0.1566],\n",
      "        [0.2302]])\n",
      "area1:tensor([[0.2976],\n",
      "        [0.4382]])\n",
      "area2:tensor([[0.6365],\n",
      "        [0.6365]])\n",
      "inter:tensor([[0.2655],\n",
      "        [0.3549]])\n",
      "union:tensor([[0.6685],\n",
      "        [0.7197]])\n",
      "area1:tensor([[0.3524],\n",
      "        [0.0328]])\n",
      "area2:tensor([[0.1098],\n",
      "        [0.1098]])\n",
      "inter:tensor([[0.0800],\n",
      "        [0.0267]])\n",
      "union:tensor([[0.3822],\n",
      "        [0.1159]])\n",
      "tensor(16.5471) tensor(8.4643) tensor(165.0612) tensor(5.0647) tensor(0.)\n",
      "tensor([0.2146, 0.2720, 0.6098, 0.8204, 0.0870, 0.4029, 0.0415, 0.4995, 0.1205,\n",
      "        0.3979, 0.1811, 0.1378, 0.1988, 0.3447, 0.7174, 0.2653, 0.4863, 0.1401,\n",
      "        0.5357, 0.6598, 0.1047, 0.0281, 0.2956, 0.7181, 0.0441, 0.0713, 0.2138,\n",
      "        0.3064, 0.5588, 0.1828, 0.5447, 0.1025, 0.0811, 0.4417, 0.1836, 0.5270,\n",
      "        0.4007, 0.7100, 0.2439, 0.2870, 0.4854, 0.5427, 0.6053, 0.5066, 0.5535,\n",
      "        0.2310, 0.1016, 0.4932, 0.2306])\n"
     ]
    }
   ],
   "source": [
    "out2 = loss_re(pre.permute(0,2,3,1),tar.permute(0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94c7dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(295.1829)\n",
      "tensor(295.1829)\n"
     ]
    }
   ],
   "source": [
    "print(out1)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39de83a",
   "metadata": {},
   "source": [
    "**损失函数正常工作，无Nan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08b8cc",
   "metadata": {},
   "source": [
    "**三、使用构建的数据集进行测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9b5591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract dataset: 100%|██████████| 13700/13700 [00:26<00:00, 514.76it/s]\n",
      "Normalize img: 100%|██████████| 13700/13700 [00:16<00:00, 835.35it/s]\n",
      "Normalize bboxes: 100%|██████████| 13700/13700 [00:00<00:00, 125795.42it/s]\n",
      "Generating targets: 100%|██████████| 13700/13700 [00:03<00:00, 4370.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.datasets import YoloData\n",
    "import torchvision\n",
    "transforms = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std  = [0.229, 0.224, 0.225]\n",
    "        ),torchvision.transforms.Resize((448,448))]\n",
    "    )\n",
    "\n",
    "# 加载数据集\n",
    "yolodata = YoloData(\"datasets/JPEGImages\",\"datasets/train.txt\",transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ec9bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "batch_size = 1\n",
    "train_iter = data.DataLoader(yolodata,batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef3ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_iter:\n",
    "    X,Y = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e4a6f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 448, 448]) torch.Size([1, 30, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb88b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.yolov1 import Yolov1\n",
    "net = Yolov1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "665436e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net(X)\n",
    "# mask = y_pred < 0\n",
    "# y_pred[mask] = 0\n",
    "# print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24b55f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2949, grad_fn=<MseLossBackward0>) tensor(0.7297, grad_fn=<MseLossBackward0>) tensor(0.9243, grad_fn=<MseLossBackward0>) tensor(2.8729e-05, grad_fn=<MseLossBackward0>) tensor(0.2928, grad_fn=<MseLossBackward0>)\n",
      "tensor([0.0054])\n",
      "area1:tensor([[0.0000],\n",
      "        [0.0025]], grad_fn=<ExpandBackward0>)\n",
      "area2:tensor([[0.4715],\n",
      "        [0.4715]])\n",
      "inter:tensor([[0.0000],\n",
      "        [0.0025]], grad_fn=<MulBackward0>)\n",
      "union:tensor([[0.4715],\n",
      "        [0.4715]], grad_fn=<SubBackward0>)\n",
      "tensor(0.2949, grad_fn=<MseLossBackward0>) tensor(0.7297, grad_fn=<MseLossBackward0>) tensor(0.9243, grad_fn=<MseLossBackward0>) tensor(2.8729e-05, grad_fn=<MseLossBackward0>) tensor(0.2928, grad_fn=<MseLossBackward0>)\n",
      "tensor([0.0054])\n"
     ]
    }
   ],
   "source": [
    "out1 = loss(y_pred,Y)\n",
    "out2 = loss_re(y_pred.permute(0,2,3,1),Y.permute(0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b1ab22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1938, grad_fn=<DivBackward0>) tensor(6.1938, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out1,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0420a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Detect_Loss_raw(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.S = feature_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "\n",
    "    def compute_iou(self, bbox1, bbox2):\n",
    "\n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "\n",
    "        lt = torch.max(\n",
    "        bbox1[:, :2].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, :2].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        rb = torch.min(\n",
    "        bbox1[:, 2:].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1] # [N, M]\n",
    "\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1]) # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1]) # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter) # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter) # [M, ] -> [1, M] -> [N, M]\n",
    "\n",
    "        union = area1 + area2 - inter # [N, M, 2]\n",
    "        iou = inter / union # [N, M, 2]\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def forward(self, pred_tensor, target_tensor):\n",
    "\n",
    "        S, B, C = self.S, self.B, self.C\n",
    "        N = 5 * B + C\n",
    "\n",
    "        batch_size = pred_tensor.size(0)\n",
    "        coord_mask = target_tensor[:, :, :, 4] > 0\n",
    "        noobj_mask = target_tensor[:, :, :, 4] == 0\n",
    "\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "\n",
    "        coord_pred = pred_tensor[coord_mask].view(-1, N)\n",
    "\n",
    "        bbox_pred = coord_pred[:, :5 * B].contiguous().view(-1,5)\n",
    "        class_pred = coord_pred[:, 5 * B:]\n",
    "\n",
    "        coord_target = target_tensor[coord_mask].view(-1,N)\n",
    "\n",
    "        bbox_target = coord_target[:, :5 * B].contiguous().view(-1, 5)\n",
    "        class_target = coord_target[:, 5 * B:]\n",
    "\n",
    "        noobj_pred = pred_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_target = target_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_conf_mask = torch.cuda.BoolTensor(noobj_pred.size()).fill_(0)\n",
    "        for b in range(B):\n",
    "            noobj_conf_mask[:, 4 + b * 5] = 1\n",
    "        noobj_pred_conf = noobj_pred[noobj_conf_mask]\n",
    "        noobj_target_conf = noobj_target[noobj_conf_mask]\n",
    "        loss_noobj = F.mse_loss(noobj_pred_conf, noobj_target_conf, reduction='sum')\n",
    "\n",
    "        coord_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(0)\n",
    "        coord_not_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(1)\n",
    "        bbox_target_iou = torch.zeros(bbox_target.size()).cuda()\n",
    "\n",
    "        for i in range(0, bbox_target.size(0), B):\n",
    "            pred = bbox_pred[i:i + B]\n",
    "            pred_xyxy = Variable(torch.FloatTensor(pred.size()))\n",
    "\n",
    "            pred_xyxy[:, :2] = pred[:, :2] / float(S) - 0.5 * pred[:, 2:4]\n",
    "            pred_xyxy[:, 2:4] = pred[:, :2] / float(S) + 0.5 * pred[:, 2:4]\n",
    "\n",
    "            target = bbox_target[i].view(-1, 5)\n",
    "            target_xyxy = Variable(torch.FloatTensor(target.size()))\n",
    "\n",
    "            target_xyxy[:, :2] = target[:, :2] / float(S) - 0.5 * target[:, 2:4]\n",
    "            target_xyxy[:, 2:4] = target[:, :2] / float(S) + 0.5 * target[:, 2:4]\n",
    "\n",
    "            iou = self.compute_iou(pred_xyxy[:, :4], target_xyxy[:, :4])\n",
    "            max_iou, max_index = iou.max(0)\n",
    "            max_index = max_index.data.cuda()\n",
    "\n",
    "            coord_response_mask[i + max_index] = 1\n",
    "            coord_not_response_mask[i+max_index] = 0\n",
    "\n",
    "            bbox_target_iou[i + max_index, torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\n",
    "        bbox_target_iou = Variable(bbox_target_iou).cuda()\n",
    "\n",
    "        bbox_pred_response = bbox_pred[coord_response_mask].view(-1, 5)\n",
    "        bbox_target_response = bbox_target[coord_response_mask].view(-1,5)\n",
    "        target_iou = bbox_target_iou[coord_response_mask].view(-1,5)\n",
    "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
    "        loss_wh = F.mse_loss(torch.sqrt(bbox_pred_response[:, 2:4]), torch.sqrt(bbox_target_response[:, 2:4]),reduction='sum')\n",
    "        loss_obj = F.mse_loss(bbox_pred_response[:, 4], target_iou[:, 4], reduction='sum')\n",
    "\n",
    "        loss_class = F.mse_loss(class_pred, class_target, reduction='sum')\n",
    "\n",
    "        print(loss_xy,loss_wh,loss_class,loss_obj,loss_noobj)\n",
    "\n",
    "        loss = self.lambda_coord * (loss_xy + loss_wh) + loss_obj + self.lambda_noobj * loss_noobj + loss_class\n",
    "        loss = loss / float(batch_size)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22edc4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2949, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.7297, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.9243, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(2.8729e-05, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.2928, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1771900/926102265.py:74: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  noobj_conf_mask = torch.cuda.BoolTensor(noobj_pred.size()).fill_(0)\n"
     ]
    }
   ],
   "source": [
    "loss2 = Detect_Loss_raw()\n",
    "device = torch.device(\"cuda:0\")\n",
    "out3 = loss2(y_pred.permute(0,2,3,1).to(device),Y.permute(0,2,3,1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "127566d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1938, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f8fc9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec5659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0927,  1.1068],\n",
      "        [ 0.3758, -0.8797]])\n",
      "tensor([[0.3045, 1.0521],\n",
      "        [0.6130,    nan]])\n"
     ]
    }
   ],
   "source": [
    "ddd = torch.randn((2,2))\n",
    "print(ddd)\n",
    "print(torch.sqrt(ddd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QwenLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
