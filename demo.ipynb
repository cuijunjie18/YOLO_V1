{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3957e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53930b6d",
   "metadata": {},
   "source": [
    "**一、定义对比实验的损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf283a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect_Loss(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "\n",
    "        super(Detect_Loss, self).__init__()\n",
    "\n",
    "        self.S = feature_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "\n",
    "    def compute_iou(self, bbox1, bbox2):\n",
    "\n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "\n",
    "        lt = torch.max(\n",
    "        bbox1[:, :2].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, :2].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        rb = torch.min(\n",
    "        bbox1[:, 2:].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1] # [N, M]\n",
    "\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1]) # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1]) # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter) # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter) # [M, ] -> [1, M] -> [N, M]\n",
    "\n",
    "        union = area1 + area2 - inter # [N, M, 2]\n",
    "        iou = inter / union # [N, M, 2]\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def forward(self, pred_tensor, target_tensor):\n",
    "\n",
    "        device = pred_tensor.device\n",
    "\n",
    "        S, B, C = self.S, self.B, self.C\n",
    "        N = 5 * B + C\n",
    "\n",
    "        batch_size = pred_tensor.size(0)\n",
    "        coord_mask = target_tensor[:, :, :, 4] > 0\n",
    "        noobj_mask = target_tensor[:, :, :, 4] == 0\n",
    "\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "\n",
    "        # breakpoint()\n",
    "\n",
    "        coord_pred = pred_tensor[coord_mask].view(-1, N)\n",
    "\n",
    "        bbox_pred = coord_pred[:, :5 * B].contiguous().view(-1,5)\n",
    "        class_pred = coord_pred[:, 5 * B:]\n",
    "\n",
    "        coord_target = target_tensor[coord_mask].view(-1,N)\n",
    "\n",
    "        bbox_target = coord_target[:, :5 * B].contiguous().view(-1, 5)\n",
    "        class_target = coord_target[:, 5 * B:]\n",
    "\n",
    "        noobj_pred = pred_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_target = target_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_conf_mask = torch.cuda.BoolTensor(noobj_pred.size()).fill_(0).to(device)\n",
    "        for b in range(B):\n",
    "            noobj_conf_mask[:, 4 + b * 5] = 1\n",
    "        noobj_pred_conf = noobj_pred[noobj_conf_mask]\n",
    "        noobj_target_conf = noobj_target[noobj_conf_mask]\n",
    "        loss_noobj = F.mse_loss(noobj_pred_conf, noobj_target_conf, reduction='sum')\n",
    "\n",
    "        coord_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(0).to(device)\n",
    "        coord_not_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(1).to(device)\n",
    "        bbox_target_iou = torch.zeros(bbox_target.size()).to(device)\n",
    "\n",
    "        for i in range(0, bbox_target.size(0), B):\n",
    "            pred = bbox_pred[i:i + B]\n",
    "            pred_xyxy = Variable(torch.FloatTensor(pred.size()))\n",
    "\n",
    "            pred_xyxy[:, :2] = pred[:, :2] / float(S) - 0.5 * pred[:, 2:4]\n",
    "            pred_xyxy[:, 2:4] = pred[:, :2] / float(S) + 0.5 * pred[:, 2:4]\n",
    "\n",
    "            target = bbox_target[i].view(-1, 5)\n",
    "            target_xyxy = Variable(torch.FloatTensor(target.size()))\n",
    "\n",
    "            target_xyxy[:, :2] = target[:, :2] / float(S) - 0.5 * target[:, 2:4]\n",
    "            target_xyxy[:, 2:4] = target[:, :2] / float(S) + 0.5 * target[:, 2:4]\n",
    "\n",
    "            iou = self.compute_iou(pred_xyxy[:, :4], target_xyxy[:, :4])\n",
    "            max_iou, max_index = iou.max(0)\n",
    "            max_index = max_index.data\n",
    "\n",
    "            coord_response_mask[i + max_index] = 1\n",
    "            coord_not_response_mask[i+max_index] = 0\n",
    "\n",
    "            bbox_target_iou[i + max_index, torch.LongTensor([4])] = (max_iou).data.to(device)\n",
    "        bbox_target_iou = Variable(bbox_target_iou).to(device)\n",
    "\n",
    "        bbox_pred_response = bbox_pred[coord_response_mask].view(-1, 5)\n",
    "        bbox_target_response = bbox_target[coord_response_mask].view(-1,5)\n",
    "        target_iou = bbox_target_iou[coord_response_mask].view(-1,5)\n",
    "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
    "        loss_wh = F.mse_loss(torch.sqrt(bbox_pred_response[:, 2:4]), torch.sqrt(bbox_target_response[:, 2:4]),reduction='sum')\n",
    "        loss_obj = F.mse_loss(bbox_pred_response[:, 4], target_iou[:, 4], reduction='sum')\n",
    "\n",
    "        loss_class = F.mse_loss(class_pred, class_target, reduction='sum')\n",
    "\n",
    "        # breakpoint()\n",
    "\n",
    "        loss = self.lambda_coord * (loss_xy + loss_wh) + loss_obj + self.lambda_noobj * loss_noobj + loss_class\n",
    "        loss = loss / float(batch_size)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454cdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    \"\"\"定义一个为yolov1的损失函数\"\"\"\n",
    "\n",
    "    def __init__(self,feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "        super().__init__()\n",
    "        self.S = feature_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "    def compute_iou(self,bbox1,bbox2):\n",
    "        \"\"\"\"\n",
    "        计算两组边界框之间的交并比(IoU)\n",
    "        \n",
    "        参数:\n",
    "        - bbox1: 形状为 [N, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        - bbox2: 形状为 [M, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        \n",
    "        返回:\n",
    "        - iou: 形状为 [N, M] 的 IoU 矩阵\n",
    "        \"\"\"\n",
    "        # 获取边界框数量\n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "        \n",
    "        # 计算交集的左上角坐标 (left-top)\n",
    "        lt = torch.max(\n",
    "            bbox1[:, :2].unsqueeze(1).expand(N, M, 2),  # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, :2].unsqueeze(0).expand(N, M, 2)   # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        \n",
    "        # 计算交集的右下角坐标 (right-bottom)\n",
    "        rb = torch.min(\n",
    "            bbox1[:, 2:].unsqueeze(1).expand(N, M, 2),  # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)    # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        \n",
    "        # 计算交集的宽高\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0  # 处理无重叠的情况\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1]  # 交集面积 [N, M]\n",
    "        \n",
    "        # 计算两个边界框各自的面积\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1])  # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1])  # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter)  # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter)  # [M, ] -> [1, M] -> [N, M]\n",
    "        \n",
    "        # 计算并集面积\n",
    "        union = area1 + area2 - inter  # [N, M]\n",
    "        \n",
    "        # 计算 IoU\n",
    "        iou = inter / union  # [N, M]\n",
    "        \n",
    "        return iou\n",
    "\n",
    "\n",
    "    def forward(self,pred:torch.Tensor,target:torch.Tensor):\n",
    "        \"\"\"\n",
    "        计算 YOLOv1 损失\n",
    "        \n",
    "        参数:\n",
    "        - pred_tensor: 模型预测的输出张量，形状为 [batch_size, S, S, B*5 + C]\n",
    "        - target_tensor: 目标标签张量，形状与 pred_tensor 相同\n",
    "        \n",
    "        返回:\n",
    "        - loss: 计算得到的损失值\n",
    "        \"\"\"\n",
    "        # target/pred = (N,C,H,W) -> (N,H,W,C)\n",
    "        device = target.device\n",
    "        target = target.permute(0,2,3,1)\n",
    "        pred = pred.permute(0,2,3,1)\n",
    "        batch_size = pred.shape[0]\n",
    "\n",
    "        # breakpoint()\n",
    "\n",
    "        # 设置临时参数，减少重复self引用\n",
    "        S = self.S\n",
    "        B = self.B\n",
    "        C = self.C\n",
    "        grid_size = 1.0 / S # 归一化的网格大小\n",
    "\n",
    "        # 设置有目标的mask和没目标的mask\n",
    "        coord_mask = target[:,:,:,4] > 0\n",
    "        noobj_mask = target[:,:,:,4] == 0\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target)\n",
    "\n",
    "        # 提取有目标的pred和没目标的pred\n",
    "        coord_pred = pred[coord_mask].reshape(-1, 5 * B + C)\n",
    "        noobj_pred = pred[noobj_mask].reshape(-1, 5 * B + C)\n",
    "\n",
    "        # 提取有目标的target和没目标的target\n",
    "        coord_target = target[coord_mask].reshape(-1, 5 * B + C)\n",
    "        noobj_target = target[noobj_mask].reshape(-1, 5 * B + C)\n",
    "\n",
    "        # 提取bbox与class\n",
    "        bbox_pred = coord_pred[:,:5 * B].reshape(-1, 5)\n",
    "        class_pred = coord_pred[:,5 * B:]\n",
    "        bbox_target = coord_target[:,:5 * B].reshape(-1, 5)\n",
    "        class_target = coord_target[:,5 * B:]\n",
    "\n",
    "        # 处理无目标位置的置信度损失\n",
    "        noobj_conf_mask = torch.BoolTensor(noobj_pred.shape).fill_(0).to(device)\n",
    "        for b in range(B):\n",
    "            noobj_conf_mask[:,4 + b * 5] = 1 # 设置提取出置信度的位置\n",
    "        noobj_conf_pred = noobj_pred[noobj_conf_mask]\n",
    "        noonj_conf_target = noobj_target[noobj_conf_mask]\n",
    "\n",
    "        # 计算noobj_loss_conf\n",
    "        loss_conf_noobj = F.mse_loss(noobj_conf_pred,noonj_conf_target,reduction = 'sum')\n",
    "\n",
    "        # 初始化响应掩码\n",
    "        coord_response_mask = torch.BoolTensor(bbox_target.size()).fill_(0).to(device) # 响应初始化为0\n",
    "        coord_not_response_mask = torch.BoolTensor(bbox_target.size()).fill_(1).to(device) # 非响应初始化为1\n",
    "        bbox_target_iou = torch.zeros(bbox_target.size()).to(device)\n",
    "\n",
    "        # 遍历每个目标网格\n",
    "        for i in range(0,bbox_pred.shape[0],B):\n",
    "            # 获取当前网格的 B 个预测边界框\n",
    "            pred = bbox_pred[i:i + B] \n",
    "\n",
    "            # 将预测边界框转换为 (xmin, ymin, xmax, ymax) 格式\n",
    "            pred_xyxy = torch.zeros((pred.shape[0],4)).to(device)\n",
    "            pred_xyxy[:,:2] = pred[:,:2] * grid_size - pred[:,2:4] * 0.5    # 左上\n",
    "            pred_xyxy[:,2:4] = pred[:,:2] * grid_size + pred[:,2:4] * 0.5   # 右下\n",
    "\n",
    "            # 同样处理出目标坐标\n",
    "            target = bbox_target[i].reshape(-1,5)\n",
    "            target_xyxy = torch.zeros((target.shape[0],4)).to(device)\n",
    "            target_xyxy[:,:2] = target[:,:2] * grid_size - target[:,2:4] * 0.5    # 左上\n",
    "            target_xyxy[:,2:4] = target[:,:2] * grid_size + target[:,2:4] * 0.5   # 右下\n",
    "\n",
    "            # 计算iou\n",
    "            iou = self.compute_iou(pred_xyxy,target_xyxy)\n",
    "            max_iou, max_index = iou.max(0)  # 找出最大 IoU 及其索引\n",
    "\n",
    "            # 标记负责预测目标的边界框\n",
    "            coord_response_mask[i + max_index] = 1\n",
    "            coord_not_response_mask[i + max_index] = 0\n",
    "\n",
    "            # 将最大 IoU 作为置信度目标\n",
    "            bbox_target_iou[i + max_index,4] = max_iou.data\n",
    "\n",
    "        # 提取负责预测目标的边界框\n",
    "        bbox_pred_response = bbox_pred[coord_response_mask].reshape(-1, 5)\n",
    "        bbox_target_response = bbox_target[coord_response_mask].reshape(-1, 5)\n",
    "        target_iou = bbox_target_iou[coord_response_mask].reshape(-1, 5)\n",
    "\n",
    "        # 计算坐标损失 (中心点坐标)\n",
    "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
    "        \n",
    "        # 计算宽高损失\n",
    "        loss_wh = F.mse_loss(\n",
    "            torch.sqrt(bbox_pred_response[:,2:4]), \n",
    "            torch.sqrt(bbox_target_response[:,2:4]), \n",
    "            reduction = 'sum'\n",
    "        )\n",
    "\n",
    "        # 计算目标置信度损失\n",
    "        loss_conf = F.mse_loss(bbox_pred_response[:,4], target_iou[:,4], reduction = 'sum')\n",
    "\n",
    "        # 计算类别预测损失\n",
    "        loss_class = F.mse_loss(class_pred,class_target,reduction = 'sum')\n",
    "\n",
    "        # breakpoint()\n",
    "\n",
    "        loss = (self.lambda_coord * (loss_xy + loss_wh) + \n",
    "                self.lambda_noobj * loss_conf_noobj +\n",
    "                loss_conf + loss_class)\n",
    "        \n",
    "        return loss / batch_size # 平均损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37b3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = YoloLoss()\n",
    "loss_re = Detect_Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869df949",
   "metadata": {},
   "source": [
    "**二、使用模拟数据进行测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249ebdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((2,2))\n",
    "mask = torch.BoolTensor([[1,1],[0,0]])\n",
    "x[mask] = 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57986865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3875, 0.0667, 0.8786,  ..., 0.9227, 0.6411, 0.3652],\n",
      "          [0.7810, 0.1526, 0.8879,  ..., 0.4373, 0.3374, 0.6314],\n",
      "          [0.3279, 0.7227, 0.7934,  ..., 0.6968, 0.5672, 0.5699],\n",
      "          ...,\n",
      "          [0.4301, 0.5339, 0.0453,  ..., 0.2022, 0.2803, 0.5357],\n",
      "          [0.1765, 0.6764, 0.2145,  ..., 0.3495, 0.6277, 0.4965],\n",
      "          [0.6739, 0.1320, 0.4863,  ..., 0.3956, 0.4727, 0.4734]],\n",
      "\n",
      "         [[0.8189, 0.8120, 0.6477,  ..., 0.3683, 0.9540, 0.0100],\n",
      "          [0.2414, 0.0621, 0.7469,  ..., 0.2494, 0.3464, 0.1221],\n",
      "          [0.4569, 0.1222, 0.4193,  ..., 0.4081, 0.1499, 0.6103],\n",
      "          ...,\n",
      "          [0.4739, 0.0052, 0.8733,  ..., 0.2954, 0.2810, 0.5989],\n",
      "          [0.7181, 0.3405, 0.3143,  ..., 0.6827, 0.4679, 0.6387],\n",
      "          [0.1674, 0.2090, 0.5196,  ..., 0.2532, 0.9658, 0.0382]],\n",
      "\n",
      "         [[0.7914, 0.4903, 0.8307,  ..., 0.8920, 0.5298, 0.9164],\n",
      "          [0.4516, 0.7117, 0.7247,  ..., 0.2350, 0.0833, 0.8645],\n",
      "          [0.2048, 0.3564, 0.5436,  ..., 0.1199, 0.2211, 0.1898],\n",
      "          ...,\n",
      "          [0.9720, 0.8192, 0.9863,  ..., 0.6836, 0.8519, 0.6991],\n",
      "          [0.8304, 0.4937, 0.1259,  ..., 0.2000, 0.0531, 0.7305],\n",
      "          [0.3131, 0.5555, 0.4063,  ..., 0.7743, 0.5930, 0.8973]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.6515, 0.4478, 0.9056,  ..., 0.5308, 0.9773, 0.8754],\n",
      "          [0.9518, 0.3627, 0.0891,  ..., 0.1094, 0.7180, 0.7592],\n",
      "          [0.9986, 0.5982, 0.2257,  ..., 0.1959, 0.4733, 0.7660],\n",
      "          ...,\n",
      "          [0.3592, 0.1662, 0.5563,  ..., 0.5589, 0.7842, 0.3820],\n",
      "          [0.5264, 0.7305, 0.2374,  ..., 0.3934, 0.1039, 0.1322],\n",
      "          [0.1420, 0.7603, 0.6918,  ..., 0.2573, 0.6856, 0.2670]],\n",
      "\n",
      "         [[0.5377, 0.5545, 0.4207,  ..., 0.8522, 0.6422, 0.3517],\n",
      "          [0.6720, 0.3958, 0.0742,  ..., 0.9727, 0.1457, 0.8423],\n",
      "          [0.3110, 0.7341, 0.9739,  ..., 0.4203, 0.9097, 0.1737],\n",
      "          ...,\n",
      "          [0.6921, 0.7288, 0.4241,  ..., 0.9885, 0.3348, 0.0349],\n",
      "          [0.8901, 0.0680, 0.3258,  ..., 0.0399, 0.5485, 0.6958],\n",
      "          [0.0223, 0.4580, 0.0519,  ..., 0.0951, 0.8503, 0.9262]],\n",
      "\n",
      "         [[0.5522, 0.5225, 0.8485,  ..., 0.3337, 0.8021, 0.2869],\n",
      "          [0.6493, 0.9271, 0.9140,  ..., 0.9468, 0.3514, 0.4788],\n",
      "          [0.6415, 0.7775, 0.6898,  ..., 0.6591, 0.6411, 0.9236],\n",
      "          ...,\n",
      "          [0.5492, 0.0421, 0.7326,  ..., 0.2452, 0.3831, 0.5301],\n",
      "          [0.2419, 0.5725, 0.8943,  ..., 0.7910, 0.3505, 0.5599],\n",
      "          [0.7604, 0.5732, 0.6716,  ..., 0.6759, 0.1259, 0.1263]]]])\n"
     ]
    }
   ],
   "source": [
    "# 注意要符合数据的要求，归一化后数值0~1\n",
    "pre = torch.rand(1,30,7,7)  # 随机预测张量 [batch, S, S, B*5+C]\n",
    "tar = torch.rand(1,30,7,7)  # 随机目标张量\n",
    "mask1 = pre > 0\n",
    "mask2 = tar > 0\n",
    "pre[~mask1] = 0\n",
    "tar[~mask2] = 0\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb05cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = loss(pre,tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb8cbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2089225/2646532065.py:73: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  noobj_conf_mask = torch.cuda.BoolTensor(noobj_pred.size()).fill_(0).to(device)\n"
     ]
    }
   ],
   "source": [
    "out2 = loss_re(pre.permute(0,2,3,1),tar.permute(0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94c7dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(295.1829)\n",
      "tensor(295.1829)\n"
     ]
    }
   ],
   "source": [
    "print(out1)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39de83a",
   "metadata": {},
   "source": [
    "**损失函数正常工作，无Nan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08b8cc",
   "metadata": {},
   "source": [
    "**三、使用构建的数据集进行测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9b5591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract dataset: 100%|██████████| 13700/13700 [00:26<00:00, 514.76it/s]\n",
      "Normalize img: 100%|██████████| 13700/13700 [00:16<00:00, 835.35it/s]\n",
      "Normalize bboxes: 100%|██████████| 13700/13700 [00:00<00:00, 125795.42it/s]\n",
      "Generating targets: 100%|██████████| 13700/13700 [00:03<00:00, 4370.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.datasets import YoloData\n",
    "import torchvision\n",
    "transforms = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Normalize(\n",
    "            mean = [0.485, 0.456, 0.406],\n",
    "            std  = [0.229, 0.224, 0.225]\n",
    "        ),torchvision.transforms.Resize((448,448))]\n",
    "    )\n",
    "\n",
    "# 加载数据集\n",
    "yolodata = YoloData(\"datasets/JPEGImages\",\"datasets/train.txt\",transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ec9bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "batch_size = 1\n",
    "train_iter = data.DataLoader(yolodata,batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ef3ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_iter:\n",
    "    X,Y = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e4a6f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 448, 448]) torch.Size([1, 30, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb88b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.yolov1 import Yolov1\n",
    "net = Yolov1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "665436e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net(X)\n",
    "# mask = y_pred < 0\n",
    "# y_pred[mask] = 0\n",
    "# print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24b55f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2949, grad_fn=<MseLossBackward0>) tensor(0.7297, grad_fn=<MseLossBackward0>) tensor(0.9243, grad_fn=<MseLossBackward0>) tensor(2.8729e-05, grad_fn=<MseLossBackward0>) tensor(0.2928, grad_fn=<MseLossBackward0>)\n",
      "tensor([0.0054])\n",
      "area1:tensor([[0.0000],\n",
      "        [0.0025]], grad_fn=<ExpandBackward0>)\n",
      "area2:tensor([[0.4715],\n",
      "        [0.4715]])\n",
      "inter:tensor([[0.0000],\n",
      "        [0.0025]], grad_fn=<MulBackward0>)\n",
      "union:tensor([[0.4715],\n",
      "        [0.4715]], grad_fn=<SubBackward0>)\n",
      "tensor(0.2949, grad_fn=<MseLossBackward0>) tensor(0.7297, grad_fn=<MseLossBackward0>) tensor(0.9243, grad_fn=<MseLossBackward0>) tensor(2.8729e-05, grad_fn=<MseLossBackward0>) tensor(0.2928, grad_fn=<MseLossBackward0>)\n",
      "tensor([0.0054])\n"
     ]
    }
   ],
   "source": [
    "out1 = loss(y_pred,Y)\n",
    "out2 = loss_re(y_pred.permute(0,2,3,1),Y.permute(0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b1ab22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1938, grad_fn=<DivBackward0>) tensor(6.1938, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out1,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0420a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Detect_Loss_raw(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.S = feature_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "\n",
    "    def compute_iou(self, bbox1, bbox2):\n",
    "\n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "\n",
    "        lt = torch.max(\n",
    "        bbox1[:, :2].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, :2].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        rb = torch.min(\n",
    "        bbox1[:, 2:].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1] # [N, M]\n",
    "\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1]) # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1]) # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter) # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter) # [M, ] -> [1, M] -> [N, M]\n",
    "\n",
    "        union = area1 + area2 - inter # [N, M, 2]\n",
    "        iou = inter / union # [N, M, 2]\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def forward(self, pred_tensor, target_tensor):\n",
    "\n",
    "        S, B, C = self.S, self.B, self.C\n",
    "        N = 5 * B + C\n",
    "\n",
    "        batch_size = pred_tensor.size(0)\n",
    "        coord_mask = target_tensor[:, :, :, 4] > 0\n",
    "        noobj_mask = target_tensor[:, :, :, 4] == 0\n",
    "\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "\n",
    "        coord_pred = pred_tensor[coord_mask].view(-1, N)\n",
    "\n",
    "        bbox_pred = coord_pred[:, :5 * B].contiguous().view(-1,5)\n",
    "        class_pred = coord_pred[:, 5 * B:]\n",
    "\n",
    "        coord_target = target_tensor[coord_mask].view(-1,N)\n",
    "\n",
    "        bbox_target = coord_target[:, :5 * B].contiguous().view(-1, 5)\n",
    "        class_target = coord_target[:, 5 * B:]\n",
    "\n",
    "        noobj_pred = pred_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_target = target_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_conf_mask = torch.cuda.BoolTensor(noobj_pred.size()).fill_(0)\n",
    "        for b in range(B):\n",
    "            noobj_conf_mask[:, 4 + b * 5] = 1\n",
    "        noobj_pred_conf = noobj_pred[noobj_conf_mask]\n",
    "        noobj_target_conf = noobj_target[noobj_conf_mask]\n",
    "        loss_noobj = F.mse_loss(noobj_pred_conf, noobj_target_conf, reduction='sum')\n",
    "\n",
    "        coord_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(0)\n",
    "        coord_not_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(1)\n",
    "        bbox_target_iou = torch.zeros(bbox_target.size()).cuda()\n",
    "\n",
    "        for i in range(0, bbox_target.size(0), B):\n",
    "            pred = bbox_pred[i:i + B]\n",
    "            pred_xyxy = Variable(torch.FloatTensor(pred.size()))\n",
    "\n",
    "            pred_xyxy[:, :2] = pred[:, :2] / float(S) - 0.5 * pred[:, 2:4]\n",
    "            pred_xyxy[:, 2:4] = pred[:, :2] / float(S) + 0.5 * pred[:, 2:4]\n",
    "\n",
    "            target = bbox_target[i].view(-1, 5)\n",
    "            target_xyxy = Variable(torch.FloatTensor(target.size()))\n",
    "\n",
    "            target_xyxy[:, :2] = target[:, :2] / float(S) - 0.5 * target[:, 2:4]\n",
    "            target_xyxy[:, 2:4] = target[:, :2] / float(S) + 0.5 * target[:, 2:4]\n",
    "\n",
    "            iou = self.compute_iou(pred_xyxy[:, :4], target_xyxy[:, :4])\n",
    "            max_iou, max_index = iou.max(0)\n",
    "            max_index = max_index.data.cuda()\n",
    "\n",
    "            coord_response_mask[i + max_index] = 1\n",
    "            coord_not_response_mask[i+max_index] = 0\n",
    "\n",
    "            bbox_target_iou[i + max_index, torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\n",
    "        bbox_target_iou = Variable(bbox_target_iou).cuda()\n",
    "\n",
    "        bbox_pred_response = bbox_pred[coord_response_mask].view(-1, 5)\n",
    "        bbox_target_response = bbox_target[coord_response_mask].view(-1,5)\n",
    "        target_iou = bbox_target_iou[coord_response_mask].view(-1,5)\n",
    "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
    "        loss_wh = F.mse_loss(torch.sqrt(bbox_pred_response[:, 2:4]), torch.sqrt(bbox_target_response[:, 2:4]),reduction='sum')\n",
    "        loss_obj = F.mse_loss(bbox_pred_response[:, 4], target_iou[:, 4], reduction='sum')\n",
    "\n",
    "        loss_class = F.mse_loss(class_pred, class_target, reduction='sum')\n",
    "\n",
    "        print(loss_xy,loss_wh,loss_class,loss_obj,loss_noobj)\n",
    "\n",
    "        loss = self.lambda_coord * (loss_xy + loss_wh) + loss_obj + self.lambda_noobj * loss_noobj + loss_class\n",
    "        loss = loss / float(batch_size)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22edc4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2949, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.7297, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.9243, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(2.8729e-05, device='cuda:0', grad_fn=<MseLossBackward0>) tensor(0.2928, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1771900/926102265.py:74: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  noobj_conf_mask = torch.cuda.BoolTensor(noobj_pred.size()).fill_(0)\n"
     ]
    }
   ],
   "source": [
    "loss2 = Detect_Loss_raw()\n",
    "device = torch.device(\"cuda:0\")\n",
    "out3 = loss2(y_pred.permute(0,2,3,1).to(device),Y.permute(0,2,3,1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "127566d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.1938, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f8fc9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec5659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0927,  1.1068],\n",
      "        [ 0.3758, -0.8797]])\n",
      "tensor([[0.3045, 1.0521],\n",
      "        [0.6130,    nan]])\n"
     ]
    }
   ],
   "source": [
    "ddd = torch.randn((2,2))\n",
    "print(ddd)\n",
    "print(torch.sqrt(ddd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QwenLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
