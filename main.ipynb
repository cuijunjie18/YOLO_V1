{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e7a72c",
   "metadata": {},
   "source": [
    "### **yolov1论文**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d1dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795a34d",
   "metadata": {},
   "source": [
    "**一、搭建模型**\n",
    "\n",
    "**backbone采用VGG架构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e84419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolov1(num_classes = 20,num_bboxes = 2):\n",
    "    \"\"\"获取yolov1o模型\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3,64,kernel_size = 7,stride = 2,padding = 3),nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(2,2),                    # k = 2,s = 2的MaxPool2d层使图像分辨率减半\n",
    "        nn.Conv2d(64,192,kernel_size = 3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "        nn.Conv2d(192,128,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(128,256,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(256,256,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(256,512,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "        nn.Conv2d(512,256,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(256,512,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(512,256,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(256,512,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(512,256,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(256,512,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(512,256,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(256,512,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(512,512,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(512,1024,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(2,2),\n",
    "        nn.Conv2d(1024,512,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(512,1024,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(1024,512,1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(512,1024,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(1024,1024,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(1024,1024,3,stride = 2,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(1024,1024,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Conv2d(1024,1024,3,padding = 1),nn.LeakyReLU(),\n",
    "        nn.Flatten(),nn.Linear(7 * 7 * 1024,4096),\n",
    "        nn.Linear(4096,7 * 7 * (num_bboxes * 5 + num_classes))\n",
    "    )\n",
    "\n",
    "class yolov1(nn.Module):\n",
    "    def __init__(self,num_classes = 20,num_bboxes = 2):\n",
    "        super().__init__()\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.layer = get_yolov1(self.C,self.B)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.layer(X)\n",
    "        X = X.reshape(X.shape[0],self.B * 5 + \n",
    "                      self.C,7,7)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba188d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = yolov1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a77355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand((1,3,448,448)) # 通道优先\n",
    "y_pred = net(input).reshape(1,30,7,7)\n",
    "# y_pred = net(input)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a7f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "yolov1                                   [1, 30, 7, 7]             --\n",
      "├─Sequential: 1-1                        [1, 1470]                 --\n",
      "│    └─Conv2d: 2-1                       [1, 64, 224, 224]         9,472\n",
      "│    └─LeakyReLU: 2-2                    [1, 64, 224, 224]         --\n",
      "│    └─MaxPool2d: 2-3                    [1, 64, 112, 112]         --\n",
      "│    └─Conv2d: 2-4                       [1, 192, 112, 112]        110,784\n",
      "│    └─LeakyReLU: 2-5                    [1, 192, 112, 112]        --\n",
      "│    └─MaxPool2d: 2-6                    [1, 192, 56, 56]          --\n",
      "│    └─Conv2d: 2-7                       [1, 128, 56, 56]          24,704\n",
      "│    └─LeakyReLU: 2-8                    [1, 128, 56, 56]          --\n",
      "│    └─Conv2d: 2-9                       [1, 256, 56, 56]          295,168\n",
      "│    └─LeakyReLU: 2-10                   [1, 256, 56, 56]          --\n",
      "│    └─Conv2d: 2-11                      [1, 256, 56, 56]          65,792\n",
      "│    └─LeakyReLU: 2-12                   [1, 256, 56, 56]          --\n",
      "│    └─Conv2d: 2-13                      [1, 512, 56, 56]          1,180,160\n",
      "│    └─LeakyReLU: 2-14                   [1, 512, 56, 56]          --\n",
      "│    └─MaxPool2d: 2-15                   [1, 512, 28, 28]          --\n",
      "│    └─Conv2d: 2-16                      [1, 256, 28, 28]          131,328\n",
      "│    └─LeakyReLU: 2-17                   [1, 256, 28, 28]          --\n",
      "│    └─Conv2d: 2-18                      [1, 512, 28, 28]          1,180,160\n",
      "│    └─LeakyReLU: 2-19                   [1, 512, 28, 28]          --\n",
      "│    └─Conv2d: 2-20                      [1, 256, 28, 28]          131,328\n",
      "│    └─LeakyReLU: 2-21                   [1, 256, 28, 28]          --\n",
      "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          1,180,160\n",
      "│    └─LeakyReLU: 2-23                   [1, 512, 28, 28]          --\n",
      "│    └─Conv2d: 2-24                      [1, 256, 28, 28]          131,328\n",
      "│    └─LeakyReLU: 2-25                   [1, 256, 28, 28]          --\n",
      "│    └─Conv2d: 2-26                      [1, 512, 28, 28]          1,180,160\n",
      "│    └─LeakyReLU: 2-27                   [1, 512, 28, 28]          --\n",
      "│    └─Conv2d: 2-28                      [1, 256, 28, 28]          131,328\n",
      "│    └─LeakyReLU: 2-29                   [1, 256, 28, 28]          --\n",
      "│    └─Conv2d: 2-30                      [1, 512, 28, 28]          1,180,160\n",
      "│    └─LeakyReLU: 2-31                   [1, 512, 28, 28]          --\n",
      "│    └─Conv2d: 2-32                      [1, 512, 28, 28]          262,656\n",
      "│    └─LeakyReLU: 2-33                   [1, 512, 28, 28]          --\n",
      "│    └─Conv2d: 2-34                      [1, 1024, 28, 28]         4,719,616\n",
      "│    └─LeakyReLU: 2-35                   [1, 1024, 28, 28]         --\n",
      "│    └─MaxPool2d: 2-36                   [1, 1024, 14, 14]         --\n",
      "│    └─Conv2d: 2-37                      [1, 512, 14, 14]          524,800\n",
      "│    └─LeakyReLU: 2-38                   [1, 512, 14, 14]          --\n",
      "│    └─Conv2d: 2-39                      [1, 1024, 14, 14]         4,719,616\n",
      "│    └─LeakyReLU: 2-40                   [1, 1024, 14, 14]         --\n",
      "│    └─Conv2d: 2-41                      [1, 512, 14, 14]          524,800\n",
      "│    └─LeakyReLU: 2-42                   [1, 512, 14, 14]          --\n",
      "│    └─Conv2d: 2-43                      [1, 1024, 14, 14]         4,719,616\n",
      "│    └─LeakyReLU: 2-44                   [1, 1024, 14, 14]         --\n",
      "│    └─Conv2d: 2-45                      [1, 1024, 14, 14]         9,438,208\n",
      "│    └─LeakyReLU: 2-46                   [1, 1024, 14, 14]         --\n",
      "│    └─Conv2d: 2-47                      [1, 1024, 7, 7]           9,438,208\n",
      "│    └─LeakyReLU: 2-48                   [1, 1024, 7, 7]           --\n",
      "│    └─Conv2d: 2-49                      [1, 1024, 7, 7]           9,438,208\n",
      "│    └─LeakyReLU: 2-50                   [1, 1024, 7, 7]           --\n",
      "│    └─Conv2d: 2-51                      [1, 1024, 7, 7]           9,438,208\n",
      "│    └─LeakyReLU: 2-52                   [1, 1024, 7, 7]           --\n",
      "│    └─Flatten: 2-53                     [1, 50176]                --\n",
      "│    └─Linear: 2-54                      [1, 4096]                 205,524,992\n",
      "│    └─Linear: 2-55                      [1, 1470]                 6,022,590\n",
      "==========================================================================================\n",
      "Total params: 271,703,550\n",
      "Trainable params: 271,703,550\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 20.30\n",
      "==========================================================================================\n",
      "Input size (MB): 2.41\n",
      "Forward/backward pass size (MB): 110.43\n",
      "Params size (MB): 1086.81\n",
      "Estimated Total Size (MB): 1199.65\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(net,input_data = input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550eae18",
   "metadata": {},
   "source": [
    "**二、定义损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db1207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Detect_Loss(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "\n",
    "        super(Detect_Loss, self).__init__()\n",
    "\n",
    "        self.S = feature_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "\n",
    "    def compute_iou(self, bbox1, bbox2):\n",
    "\n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "\n",
    "        lt = torch.max(\n",
    "        bbox1[:, :2].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, :2].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        rb = torch.min(\n",
    "        bbox1[:, 2:].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "            )\n",
    "\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1] # [N, M]\n",
    "\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1]) # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1]) # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter) # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter) # [M, ] -> [1, M] -> [N, M]\n",
    "\n",
    "        union = area1 + area2 - inter # [N, M, 2]\n",
    "        iou = inter / union # [N, M, 2]\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def forward(self, pred_tensor, target_tensor):\n",
    "\n",
    "        S, B, C = self.S, self.B, self.C\n",
    "        N = 5 * B + C\n",
    "\n",
    "        batch_size = pred_tensor.size(0)\n",
    "        coord_mask = target_tensor[:, :, :, 4] > 0\n",
    "        noobj_mask = target_tensor[:, :, :, 4] == 0\n",
    "\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target_tensor)\n",
    "\n",
    "        coord_pred = pred_tensor[coord_mask].view(-1, N)\n",
    "\n",
    "        bbox_pred = coord_pred[:, :5 * B].contiguous().view(-1,5)\n",
    "        class_pred = coord_pred[:, 5 * B:]\n",
    "\n",
    "        coord_target = target_tensor[coord_mask].view(-1,N)\n",
    "\n",
    "        bbox_target = coord_target[:, :5 * B].contiguous().view(-1, 5)\n",
    "        class_target = coord_target[:, 5 * B:]\n",
    "\n",
    "        noobj_pred = pred_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_target = target_tensor[noobj_mask].view(-1,N)\n",
    "\n",
    "        noobj_conf_mask = torch.cuda.BoolTensor(noobj_pred.size()).fill_(0)\n",
    "        for b in range(B):\n",
    "            noobj_conf_mask[:, 4 + b * 5] = 1\n",
    "        noobj_pred_conf = noobj_pred[noobj_conf_mask]\n",
    "        noobj_target_conf = noobj_target[noobj_conf_mask]\n",
    "        loss_noobj = F.mse_loss(noobj_pred_conf, noobj_target_conf, reduction='sum')\n",
    "\n",
    "        coord_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(0)\n",
    "        coord_not_response_mask = torch.cuda.BoolTensor(bbox_target.size()).fill_(1)\n",
    "        bbox_target_iou = torch.zeros(bbox_target.size()).cuda()\n",
    "\n",
    "        for i in range(0, bbox_target.size(0), B):\n",
    "            pred = bbox_pred[i:i + B]\n",
    "            pred_xyxy = Variable(torch.FloatTensor(pred.size()))\n",
    "\n",
    "            pred_xyxy[:, :2] = pred[:, :2] / float(S) - 0.5 * pred[:, 2:4]\n",
    "            pred_xyxy[:, 2:4] = pred[:, :2] / float(S) + 0.5 * pred[:, 2:4]\n",
    "\n",
    "            target = bbox_target[i].view(-1, 5)\n",
    "            target_xyxy = Variable(torch.FloatTensor(target.size()))\n",
    "\n",
    "            target_xyxy[:, :2] = target[:, :2] / float(S) - 0.5 * target[:, 2:4]\n",
    "            target_xyxy[:, 2:4] = target[:, :2] / float(S) + 0.5 * target[:, 2:4]\n",
    "\n",
    "            iou = self.compute_iou(pred_xyxy[:, :4], target_xyxy[:, :4])\n",
    "            max_iou, max_index = iou.max(0)\n",
    "            max_index = max_index.data.cuda()\n",
    "\n",
    "            coord_response_mask[i + max_index] = 1\n",
    "            coord_not_response_mask[i+max_index] = 0\n",
    "\n",
    "            bbox_target_iou[i + max_index, torch.LongTensor([4]).cuda()] = (max_iou).data.cuda()\n",
    "        bbox_target_iou = Variable(bbox_target_iou).cuda()\n",
    "\n",
    "        bbox_pred_response = bbox_pred[coord_response_mask].view(-1, 5)\n",
    "        bbox_target_response = bbox_target[coord_response_mask].view(-1,5)\n",
    "        target_iou = bbox_target_iou[coord_response_mask].view(-1,5)\n",
    "        loss_xy = F.mse_loss(bbox_pred_response[:, :2], bbox_target_response[:, :2], reduction='sum')\n",
    "        loss_wh = F.mse_loss(torch.sqrt(bbox_pred_response[:, 2:4]), torch.sqrt(bbox_target_response[:, 2:4]),reduction='sum')\n",
    "        loss_obj = F.mse_loss(bbox_pred_response[:, 4], target_iou[:, 4], reduction='sum')\n",
    "\n",
    "        loss_class = F.mse_loss(class_pred, class_target, reduction='sum')\n",
    "\n",
    "        loss = self.lambda_coord * (loss_xy + loss_wh) + loss_obj + self.lambda_noobj * loss_noobj + loss_class\n",
    "        loss = loss / float(batch_size)\n",
    "\n",
    "        return loss_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d9ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    \"\"\"定义一个为yolov1的损失函数\"\"\"\n",
    "\n",
    "    def __init__(self,feature_size=7, num_bboxes=2, num_classes=20, lambda_coord=5.0, lambda_noobj=0.5):\n",
    "        super().__init__()\n",
    "        self.S = feature_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "    def compute_iou(self,bbox1,bbox2):\n",
    "        \"\"\"\"\n",
    "        计算两组边界框之间的交并比(IoU)\n",
    "        \n",
    "        参数:\n",
    "        - bbox1: 形状为 [N, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        - bbox2: 形状为 [M, 4] 的边界框 (xmin, ymin, xmax, ymax)\n",
    "        \n",
    "        返回:\n",
    "        - iou: 形状为 [N, M] 的 IoU 矩阵\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def forward(self,pred,target):\n",
    "        \"\"\"\n",
    "        计算 YOLOv1 损失\n",
    "        \n",
    "        参数:\n",
    "        - pred_tensor: 模型预测的输出张量，形状为 [batch_size, S, S, B*5 + C]\n",
    "        - target_tensor: 目标标签张量，形状与 pred_tensor 相同\n",
    "        \n",
    "        返回:\n",
    "        - loss: 计算得到的损失值\n",
    "        \"\"\"\n",
    "        # target/pred = (N,C,H,W) -> (N,H,W,C)\n",
    "        target = target.permute(0,2,3,1)\n",
    "        pred = pred.permute(0,2,3,1)\n",
    "\n",
    "        # 设置临时参数，减少重复self引用\n",
    "        S = self.S\n",
    "        B = self.B\n",
    "        C = self.C\n",
    "        grid_size = 1.0 / S # 归一化的网格大小\n",
    "\n",
    "        coord_mask = target[:,:,:,4] > 0\n",
    "        noobj_mask = target[:,:,:,4] == 0\n",
    "        coord_mask = coord_mask.expand_as(target)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57379104",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = YoloLoss()\n",
    "loss2 = Detect_Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2c8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randn((1,7,7,30)).to('cuda')\n",
    "y_pred = torch.randn((1,7,7,30)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ea3181",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (7) must match the existing size (30) at non-singleton dimension 3.  Target sizes: [1, 7, 30, 7].  Tensor sizes: [1, 7, 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_xy1 \u001b[38;5;241m=\u001b[39m \u001b[43mloss1\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m loss_xy2 \u001b[38;5;241m=\u001b[39m loss2(y_pred,target)\n",
      "File \u001b[0;32m/data_all/cjj_node/local/anaconda3/envs/QwenLM/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data_all/cjj_node/local/anaconda3/envs/QwenLM/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 48\u001b[0m, in \u001b[0;36mYoloLoss.forward\u001b[0;34m(self, pred, target)\u001b[0m\n\u001b[1;32m     46\u001b[0m coord_mask \u001b[38;5;241m=\u001b[39m target[:,:,:,\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     47\u001b[0m noobj_mask \u001b[38;5;241m=\u001b[39m target[:,:,:,\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 48\u001b[0m coord_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcoord_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (7) must match the existing size (30) at non-singleton dimension 3.  Target sizes: [1, 7, 30, 7].  Tensor sizes: [1, 7, 30]"
     ]
    }
   ],
   "source": [
    "loss_xy1 = loss1(y_pred,target)\n",
    "loss_xy2 = loss2(y_pred,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf764873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(213.9551, device='cuda:0')\n",
      "tensor(100.8497, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(loss_xy1)\n",
    "print(loss_xy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b44fa41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 7, 30])\n",
      "torch.Size([780])\n",
      "torch.Size([39, 20]) torch.Size([39, 20])\n"
     ]
    }
   ],
   "source": [
    "# batch_size = y_pred.size(0)\n",
    "coord_mask = target[:, :, :, 4] > 0\n",
    "noobj_mask = target[:, :, :, 4] == 0\n",
    "coord_mask = coord_mask.unsqueeze(-1).expand_as(target)\n",
    "noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target)\n",
    "# 提取有目标位置的预测值和目标值\n",
    "print(y_pred.shape)\n",
    "print(y_pred[coord_mask].shape)\n",
    "coord_pred = y_pred[coord_mask].view(-1, 20)\n",
    "coord_target = target[coord_mask].view(-1, 20)\n",
    "print(coord_pred.shape,coord_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67ce07e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78, 5])\n"
     ]
    }
   ],
   "source": [
    "bbox_pred = coord_pred[:, :5 * 2].contiguous().view(-1, 5)\n",
    "print(bbox_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc41f70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37363])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,50,50,30))\n",
    "mask = torch.randn((1,50,50,30)) > 0\n",
    "y = x[mask]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c3dafab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.9819, 0.9927]),\n",
      "indices=tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2,2))\n",
    "print(x.max(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QwenLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
